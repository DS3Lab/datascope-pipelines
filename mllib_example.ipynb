{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Create mllib pipeline\n",
    "from dspipes import Pipelines, MllibPipelines, RumblePipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rumble Pipelines (write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic 0\n",
      "logistic 1\n",
      "logistic 3\n",
      "logistic 5\n",
      "RandomForest 0\n",
      "RandomForest 1\n",
      "RandomForest 3\n",
      "RandomForest 5\n",
      "LinearSVC 0\n",
      "LinearSVC 1\n",
      "LinearSVC 3\n",
      "LinearSVC 5\n",
      "NB 0\n",
      "NB 1\n",
      "NB 3\n",
      "NB 5\n"
     ]
    }
   ],
   "source": [
    "MODELS = ['logistic', 'RandomForest', 'LinearSVC', 'NB']\n",
    "ALL_PIPELINES = [0, 1, 3, 5]\n",
    "DATASET = 'Criteo'\n",
    "for m in MODELS:\n",
    "    for i in ALL_PIPELINES:\n",
    "        print(m, i)\n",
    "        program = RumblePipelines.create_rumble_program(f\"pipe_{i}\", clf_mode=f\"{m}\")\n",
    "        f = open(f\"./rumble_experiment_scripts/query_{i}_{m}_{DATASET}.rumble\", \"w\")\n",
    "        f.write(program)\n",
    "        f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = ['logistic', 'RandomForest', 'LinearSVC', 'NB']\n",
    "ALL_PIPELINES = [0, 1, 3, 5]\n",
    "DATASET = 'Criteo'\n",
    "f = open(f\"run_rumble_experiments.sh\", \"a\")\n",
    "for m in MODELS:\n",
    "    for i in ALL_PIPELINES:\n",
    "        res = f\"time spark-submit --num-executors 3 --executor-cores 1 --executor-memory 19g rumbledb-1.16.0.jar --query-path './rumble_experiment_scripts/query_{i}_{m}_{DATASET}.rumble'\\n\"\n",
    "        f.write(res)\n",
    "f.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%rumble\n",
      "declare type local:mytype as {\"id\": \"integer\", \"label\": \"integer\", \"col1\": \"decimal\", \"col2\": \"decimal\", \"col3\": \"decimal\"};\n",
      "let $training-data := validate type local:mytype* {\n",
      "    {\"id\": 0, \"label\": 1, \"col1\": 0.0, \"col2\": 1.1, \"col3\": 0.1},\n",
      "    {\"id\": 1, \"label\": 0, \"col1\": 2.0, \"col2\": 1.0, \"col3\": -1.0},\n",
      "    {\"id\": 2, \"label\": 0, \"col1\": 2.0, \"col2\": 1.3, \"col3\": 1.0},\n",
      "    {\"id\": 3, \"label\": 1, \"col1\": 0.0, \"col2\": 1.2, \"col3\": -0.5}\n",
      "    }\n",
      "let $test-data := validate type local:mytype* {\n",
      "    {\"id\": 0, \"label\": 1, \"col1\": -1.0, \"col2\": 1.5, \"col3\": 1.3},\n",
      "    {\"id\": 1, \"label\": 0, \"col1\": 3.0, \"col2\": 2.0, \"col3\": -0.1},\n",
      "    {\"id\": 2, \"label\": 1, \"col1\": 0.0, \"col2\": 2.2, \"col3\": -1.5}\n",
      "    }\n",
      "let $vector-assembler := get-transformer(\"VectorAssembler\", {\"inputCols\" : [ \"col1\", \"col2\", \"col3\" ], \"outputCol\" : \"features\"})\n",
      "let $scaler := get-estimator(\"MaxAbsScaler\", {\"inputCol\": \"features\", \"outputCol\": \"transformedFeatures\"})\n",
      "let $logisticregression := get-estimator(\"LogisticRegression\", {\"featuresCol\": \"transformedFeatures\"})\n",
      "let $pipeline := get-estimator(\"Pipeline\", {\"stages\": [$vector-assembler, $scaler, $logisticregression]})\n",
      "let $pip := $pipeline($training-data, {})\n",
      "return $pip($test-data, {})\n"
     ]
    }
   ],
   "source": [
    "program = RumblePipelines.create_rumble_program(\"pipe_1\")\n",
    "print(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%rumble\n",
      "declare type local:mytype as {\"id\": \"integer\", \"label\": \"integer\", \"col1\": \"decimal\", \"col2\": \"decimal\", \"col3\": \"decimal\"};\n",
      "let $training-data := validate type local:mytype* {\n",
      "    {\"id\": 0, \"label\": 1, \"col1\": 0.0, \"col2\": 1.1, \"col3\": 0.1},\n",
      "    {\"id\": 1, \"label\": 0, \"col1\": 2.0, \"col2\": 1.0, \"col3\": -1.0},\n",
      "    {\"id\": 2, \"label\": 0, \"col1\": 2.0, \"col2\": 1.3, \"col3\": 1.0},\n",
      "    {\"id\": 3, \"label\": 1, \"col1\": 0.0, \"col2\": 1.2, \"col3\": -0.5}\n",
      "    }\n",
      "let $test-data := validate type local:mytype* {\n",
      "    {\"id\": 0, \"label\": 1, \"col1\": -1.0, \"col2\": 1.5, \"col3\": 1.3},\n",
      "    {\"id\": 1, \"label\": 0, \"col1\": 3.0, \"col2\": 2.0, \"col3\": -0.1},\n",
      "    {\"id\": 2, \"label\": 1, \"col1\": 0.0, \"col2\": 2.2, \"col3\": -1.5}\n",
      "    }\n",
      "let $vector-assembler := get-transformer(\"VectorAssembler\", {\"inputCols\" : [ \"col1\", \"col2\", \"col3\" ], \"outputCol\" : \"features\"})\n",
      "let $pca := get-estimator(\"PCA\", {\"inputCol\": \"features\", \"outputCol\": \"transformedFeatures\", \"k\": 2})\n",
      "let $logisticregression := get-estimator(\"LogisticRegression\", {\"featuresCol\": \"transformedFeatures\"})\n",
      "let $pipeline := get-estimator(\"Pipeline\", {\"stages\": [$vector-assembler, $pca, $logisticregression]})\n",
      "let $pip := $pipeline($training-data, {})\n",
      "return $pip($test-data, {})\n"
     ]
    }
   ],
   "source": [
    "program = RumblePipelines.create_rumble_program(\"pipe_3\")\n",
    "print(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%rumble\n",
      "declare type local:mytype as {\"id\": \"integer\", \"label\": \"integer\", \"col1\": \"decimal\", \"col2\": \"decimal\", \"col3\": \"decimal\"};\n",
      "let $training-data := validate type local:mytype* {\n",
      "    {\"id\": 0, \"label\": 1, \"col1\": 0.0, \"col2\": 1.1, \"col3\": 0.1},\n",
      "    {\"id\": 1, \"label\": 0, \"col1\": 2.0, \"col2\": 1.0, \"col3\": -1.0},\n",
      "    {\"id\": 2, \"label\": 0, \"col1\": 2.0, \"col2\": 1.3, \"col3\": 1.0},\n",
      "    {\"id\": 3, \"label\": 1, \"col1\": 0.0, \"col2\": 1.2, \"col3\": -0.5}\n",
      "    }\n",
      "let $test-data := validate type local:mytype* {\n",
      "    {\"id\": 0, \"label\": 1, \"col1\": -1.0, \"col2\": 1.5, \"col3\": 1.3},\n",
      "    {\"id\": 1, \"label\": 0, \"col1\": 3.0, \"col2\": 2.0, \"col3\": -0.1},\n",
      "    {\"id\": 2, \"label\": 1, \"col1\": 0.0, \"col2\": 2.2, \"col3\": -1.5}\n",
      "    }\n",
      "let $vector-assembler := get-transformer(\"VectorAssembler\", {\"inputCols\" : [ \"col1\", \"col2\", \"col3\" ], \"outputCol\" : \"features\"})\n",
      "let $pca := get-estimator(\"PCA\", {\"inputCol\": \"features\", \"outputCol\": \"pca_1_output\", \"k\": 2})\n",
      "let $pca2 := get-estimator(\"PCA\", {\"inputCol\": \"features\", \"outputCol\": \"pca_2_output\", \"k\": 3})\n",
      "let $vector-assembler_2 := get-transformer(\"VectorAssembler\", {\"inputCols\" : [\"pca_1_output\",\"pca_2_output\"], \"outputCol\" : \"transformedFeatures\"})\n",
      "let $naivebayes := get-estimator(\"NaiveBayes\", {\"featuresCol\": \"transformedFeatures\"})\n",
      "let $pipeline := get-estimator(\"Pipeline\", {\"stages\": [$vector-assembler, $pca, $pca2, $vector-assembler_2, $naivebayes]})\n",
      "let $pip := $pipeline($training-data, {})\n",
      "return $pip($test-data, {})\n"
     ]
    }
   ],
   "source": [
    "program = RumblePipelines.create_rumble_program(\"pipe_5\", clf_mode='NB')\n",
    "print(program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLlib Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkContext(\"local\", \"First App\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Prepare training data from a list of (label, features) tuples.\n",
    "training = spark.createDataFrame([\n",
    "    (1.0, Vectors.dense([0.0, 1.1, 0.1])),\n",
    "    (0.0, Vectors.dense([2.0, 1.0, -1.0])),\n",
    "    (0.0, Vectors.dense([2.0, 1.3, 1.0])),\n",
    "    (1.0, Vectors.dense([0.0, 1.2, -0.5]))], [\"label\", \"features\"])\n",
    "\n",
    "test = spark.createDataFrame([\n",
    "    (1.0, Vectors.dense([-1.0, 1.5, 1.3])),\n",
    "    (0.0, Vectors.dense([3.0, 2.0, -0.1])),\n",
    "    (1.0, Vectors.dense([0.0, 2.2, -1.5]))], [\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='Pipeline_400199c7d508', name='stages', doc='a list of pipeline stages'): [LogisticRegression_2944e69ebd33]}\n"
     ]
    }
   ],
   "source": [
    "#0,1,3,5\n",
    "pipeline = MllibPipelines.create_numerical_pipeline('pipe_0', imputer=False)\n",
    "print(pipeline.extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features=[-1.0,1.5,1.3], label=1.0 -> prob=[1.5982302680575156e-19,1.0], prediction=1.0\n",
      "features=[3.0,2.0,-0.1], label=0.0 -> prob=[0.9999999999983489,1.6511236822225328e-12], prediction=0.0\n",
      "features=[0.0,2.2,-1.5], label=1.0 -> prob=[9.067197386387449e-19,1.0], prediction=1.0\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(test)\n",
    "result = prediction.select(\"features\", \"label\", \"probability\", \"prediction\") \\\n",
    "    .collect()\n",
    "\n",
    "for row in result:\n",
    "    print(\"features=%s, label=%s -> prob=%s, prediction=%s\"\n",
    "          % (row.features, row.label, row.probability, row.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
