{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Create mllib pipeline\n",
    "from dspipes import Pipelines, MllibPipelines, RumblePipelines"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rumble Pipelines"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "program = RumblePipelines.create_rumble_program(\"pipe_5\")\n",
    "print(program)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "%%rumble\n",
      "let $training-data := parquet-file(\"/Users/david/Projects/pipelines/data/uci.parquet\")\n",
      "let $test-data := parquet-file(\"/Users/david/Projects/pipelines/data/uci_test.parquet\")\n",
      "let $vector-assembler := get-transformer(\"VectorAssembler\", {\"inputCols\" : [ \"col_0\", \"col_1\", \"col_2\", \"col_3\", \"col_4\", \"col_5\", \"col_6\", \"col_7\", \"col_8\", \"col_9\", \"col_10\", \"col_11\", \"col_12\", \"col_13\" ], \"outputCol\" : \"features\"})\n",
      "let $pca := get-estimator(\"PCA\", {\"inputCol\": \"features\", \"outputCol\": \"pca_1_output\", \"k\": 2})\n",
      "let $pca2 := get-estimator(\"PCA\", {\"inputCol\": \"features\", \"outputCol\": \"pca_2_output\", \"k\": 3})\n",
      "let $vector-assembler_2 := get-transformer(\"VectorAssembler\", {\"inputCols\" : [\"pca_1_output\",\"pca_2_output\"], \"outputCol\" : \"transformedFeatures\"})\n",
      "let $logisticregression := get-estimator(\"LogisticRegression\", {\"featuresCol\": \"transformedFeatures\"})\n",
      "let $pipeline := get-estimator(\"Pipeline\", {\"stages\": [$vector-assembler, $pca, $pca2, $vector-assembler_2, $logisticregression]})\n",
      "let $pip := $pipeline($training-data, {})\n",
      "return $pip($test-data, {})\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "program = RumblePipelines.create_rumble_program(\"pipe_1\")\n",
    "print(program)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "%%rumble\n",
      "declare type local:mytype as {\"id\": \"integer\", \"label\": \"integer\", \"col1\": \"decimal\", \"col2\": \"decimal\", \"col3\": \"decimal\"};\n",
      "let $training-data := validate type local:mytype* {\n",
      "    {\"id\": 0, \"label\": 1, \"col1\": 0.0, \"col2\": 1.1, \"col3\": 0.1},\n",
      "    {\"id\": 1, \"label\": 0, \"col1\": 2.0, \"col2\": 1.0, \"col3\": -1.0},\n",
      "    {\"id\": 2, \"label\": 0, \"col1\": 2.0, \"col2\": 1.3, \"col3\": 1.0},\n",
      "    {\"id\": 3, \"label\": 1, \"col1\": 0.0, \"col2\": 1.2, \"col3\": -0.5}\n",
      "    }\n",
      "let $test-data := validate type local:mytype* {\n",
      "    {\"id\": 0, \"label\": 1, \"col1\": -1.0, \"col2\": 1.5, \"col3\": 1.3},\n",
      "    {\"id\": 1, \"label\": 0, \"col1\": 3.0, \"col2\": 2.0, \"col3\": -0.1},\n",
      "    {\"id\": 2, \"label\": 1, \"col1\": 0.0, \"col2\": 2.2, \"col3\": -1.5}\n",
      "    }\n",
      "let $vector-assembler := get-transformer(\"VectorAssembler\", {\"inputCols\" : [ \"col1\", \"col2\", \"col3\" ], \"outputCol\" : \"features\"})\n",
      "let $scaler := get-estimator(\"MaxAbsScaler\", {\"inputCol\": \"features\", \"outputCol\": \"transformedFeatures\"})\n",
      "let $logisticregression := get-estimator(\"LogisticRegression\", {\"featuresCol\": \"transformedFeatures\"})\n",
      "let $pipeline := get-estimator(\"Pipeline\", {\"stages\": [$vector-assembler, $scaler, $logisticregression]})\n",
      "let $pip := $pipeline($training-data, {})\n",
      "return $pip($test-data, {})\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "program = RumblePipelines.create_rumble_program(\"pipe_3\")\n",
    "print(program)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "%%rumble\n",
      "declare type local:mytype as {\"id\": \"integer\", \"label\": \"integer\", \"col1\": \"decimal\", \"col2\": \"decimal\", \"col3\": \"decimal\"};\n",
      "let $training-data := validate type local:mytype* {\n",
      "    {\"id\": 0, \"label\": 1, \"col1\": 0.0, \"col2\": 1.1, \"col3\": 0.1},\n",
      "    {\"id\": 1, \"label\": 0, \"col1\": 2.0, \"col2\": 1.0, \"col3\": -1.0},\n",
      "    {\"id\": 2, \"label\": 0, \"col1\": 2.0, \"col2\": 1.3, \"col3\": 1.0},\n",
      "    {\"id\": 3, \"label\": 1, \"col1\": 0.0, \"col2\": 1.2, \"col3\": -0.5}\n",
      "    }\n",
      "let $test-data := validate type local:mytype* {\n",
      "    {\"id\": 0, \"label\": 1, \"col1\": -1.0, \"col2\": 1.5, \"col3\": 1.3},\n",
      "    {\"id\": 1, \"label\": 0, \"col1\": 3.0, \"col2\": 2.0, \"col3\": -0.1},\n",
      "    {\"id\": 2, \"label\": 1, \"col1\": 0.0, \"col2\": 2.2, \"col3\": -1.5}\n",
      "    }\n",
      "let $vector-assembler := get-transformer(\"VectorAssembler\", {\"inputCols\" : [ \"col1\", \"col2\", \"col3\" ], \"outputCol\" : \"features\"})\n",
      "let $pca := get-estimator(\"PCA\", {\"inputCol\": \"features\", \"outputCol\": \"transformedFeatures\", \"k\": 2})\n",
      "let $logisticregression := get-estimator(\"LogisticRegression\", {\"featuresCol\": \"transformedFeatures\"})\n",
      "let $pipeline := get-estimator(\"Pipeline\", {\"stages\": [$vector-assembler, $pca, $logisticregression]})\n",
      "let $pip := $pipeline($training-data, {})\n",
      "return $pip($test-data, {})\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "program = RumblePipelines.create_rumble_program(\"pipe_5\", clf_mode='NB')\n",
    "print(program)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "%%rumble\n",
      "declare type local:mytype as {\"id\": \"integer\", \"label\": \"integer\", \"col1\": \"decimal\", \"col2\": \"decimal\", \"col3\": \"decimal\"};\n",
      "let $training-data := validate type local:mytype* {\n",
      "    {\"id\": 0, \"label\": 1, \"col1\": 0.0, \"col2\": 1.1, \"col3\": 0.1},\n",
      "    {\"id\": 1, \"label\": 0, \"col1\": 2.0, \"col2\": 1.0, \"col3\": -1.0},\n",
      "    {\"id\": 2, \"label\": 0, \"col1\": 2.0, \"col2\": 1.3, \"col3\": 1.0},\n",
      "    {\"id\": 3, \"label\": 1, \"col1\": 0.0, \"col2\": 1.2, \"col3\": -0.5}\n",
      "    }\n",
      "let $test-data := validate type local:mytype* {\n",
      "    {\"id\": 0, \"label\": 1, \"col1\": -1.0, \"col2\": 1.5, \"col3\": 1.3},\n",
      "    {\"id\": 1, \"label\": 0, \"col1\": 3.0, \"col2\": 2.0, \"col3\": -0.1},\n",
      "    {\"id\": 2, \"label\": 1, \"col1\": 0.0, \"col2\": 2.2, \"col3\": -1.5}\n",
      "    }\n",
      "let $vector-assembler := get-transformer(\"VectorAssembler\", {\"inputCols\" : [ \"col1\", \"col2\", \"col3\" ], \"outputCol\" : \"features\"})\n",
      "let $pca := get-estimator(\"PCA\", {\"inputCol\": \"features\", \"outputCol\": \"pca_1_output\", \"k\": 2})\n",
      "let $pca2 := get-estimator(\"PCA\", {\"inputCol\": \"features\", \"outputCol\": \"pca_2_output\", \"k\": 3})\n",
      "let $vector-assembler_2 := get-transformer(\"VectorAssembler\", {\"inputCols\" : [\"pca_1_output\",\"pca_2_output\"], \"outputCol\" : \"transformedFeatures\"})\n",
      "let $naivebayes := get-estimator(\"NaiveBayes\", {\"featuresCol\": \"transformedFeatures\"})\n",
      "let $pipeline := get-estimator(\"Pipeline\", {\"stages\": [$vector-assembler, $pca, $pca2, $vector-assembler_2, $naivebayes]})\n",
      "let $pip := $pipeline($training-data, {})\n",
      "return $pip($test-data, {})\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MLlib Pipelines"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkContext(\"local\", \"First App\")\n",
    "spark = SparkSession(sc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Define data\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Prepare training data from a list of (label, features) tuples.\n",
    "training = spark.createDataFrame([\n",
    "    (1.0, Vectors.dense([0.0, 1.1, 0.1])),\n",
    "    (0.0, Vectors.dense([2.0, 1.0, -1.0])),\n",
    "    (0.0, Vectors.dense([2.0, 1.3, 1.0])),\n",
    "    (1.0, Vectors.dense([0.0, 1.2, -0.5]))], [\"label\", \"features\"])\n",
    "\n",
    "test = spark.createDataFrame([\n",
    "    (1.0, Vectors.dense([-1.0, 1.5, 1.3])),\n",
    "    (0.0, Vectors.dense([3.0, 2.0, -0.1])),\n",
    "    (1.0, Vectors.dense([0.0, 2.2, -1.5]))], [\"label\", \"features\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#0,1,3,5\n",
    "pipeline = MllibPipelines.create_numerical_pipeline('pipe_0', imputer=False)\n",
    "print(pipeline.extractParamMap())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{Param(parent='Pipeline_400199c7d508', name='stages', doc='a list of pipeline stages'): [LogisticRegression_2944e69ebd33]}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "model = pipeline.fit(training)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "prediction = model.transform(test)\n",
    "result = prediction.select(\"features\", \"label\", \"probability\", \"prediction\") \\\n",
    "    .collect()\n",
    "\n",
    "for row in result:\n",
    "    print(\"features=%s, label=%s -> prob=%s, prediction=%s\"\n",
    "          % (row.features, row.label, row.probability, row.prediction))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "features=[-1.0,1.5,1.3], label=1.0 -> prob=[1.5982302680575156e-19,1.0], prediction=1.0\n",
      "features=[3.0,2.0,-0.1], label=0.0 -> prob=[0.9999999999983489,1.6511236822225328e-12], prediction=0.0\n",
      "features=[0.0,2.2,-1.5], label=1.0 -> prob=[9.067197386387449e-19,1.0], prediction=1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "interpreter": {
   "hash": "e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}